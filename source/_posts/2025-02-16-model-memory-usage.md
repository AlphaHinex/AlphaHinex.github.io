---
id: model-memory-usage
title: "å¯æœ¬åœ°éƒ¨ç½²ä½¿ç”¨çš„å¤§æ¨¡å‹æ˜¾å­˜èµ„æºä¼°ç®—å·¥å…·"
description: "è§£å†³çº¿ä¸Šç‰ˆæœ¬å½“å‰æ— æ³•æ­£å¸¸ä½¿ç”¨ä»¥åŠæ— æ³•è®¿é—®çš„é—®é¢˜"
date: 2025.02.16 10:34
categories:
    - AI
    - Python
tags: [AI, Python, HuggingFace, LLM]
keywords: Hugging Face, Model Memory Calculator, Accelerate, Model was not found on the Hub
cover: /contents/model-memory-usage/cover.png
---

[ğŸ¤— Model Memory Calculator](https://huggingface.co/spaces/hf-accelerate/model-memory-usage) æ˜¯ [ğŸ¤— Accelerate](https://github.com/huggingface/accelerate) åº“æä¾›çš„ä¸€ä¸ªæ¨¡å‹æ˜¾å­˜è®¡ç®—å·¥å…·ï¼Œå¯ä¼°ç®—æ¨¡å‹è®­ç»ƒæˆ–æ¨ç†æ—¶æ‰€éœ€çš„æ˜¾å­˜å¤§å°ã€‚

ä½†ç›®å‰è¯¥åœ¨çº¿å·¥å…·æ— æ³•æ­£å¸¸ä½¿ç”¨ï¼Œå³ä½¿ä½¿ç”¨é»˜è®¤çš„æ¨¡å‹åç§°ï¼Œä¹Ÿä¼šæŠ¥åœ¨ Hub ä¸­æ— æ³•æ‰¾åˆ°è¯¥æ¨¡å‹ï¼š

![not found](/contents/model-memory-usage/not-found.png)

åœ¨è¯¥ space çš„ [discussions](https://huggingface.co/spaces/hf-accelerate/model-memory-usage/discussions) ä¸­ä¹Ÿæœ‰ä¸å°‘äººé‡åˆ°äº†æ­¤é—®é¢˜ã€‚

æœ¬æ–‡æä¾›ä¸€ç§æœ¬åœ°åŒ–éƒ¨ç½²è¿è¡Œæ­¤å·¥å…·çš„æ–¹æ³•ï¼Œè¿˜å¯é€šè¿‡æŒ‡å®š `HF_ENDPOINT` é¿å…æ— æ³•è®¿é—® Hugging Face çš„é—®é¢˜ã€‚

æœ¬åœ°éƒ¨ç½²
=======

hotfix ç‰ˆæœ¬
-----------

ç›´æ¥éƒ¨ç½² https://huggingface.co/spaces/hf-accelerate/model-memory-usage/tree/main ä¸­çš„å†…å®¹ä¼šé‡åˆ°ä¸€äº›é—®é¢˜ï¼Œå¯ä½¿ç”¨ [hotfix](https://github.com/AlphaHinex/model-memory-usage) åˆ†æ”¯çš„ç‰ˆæœ¬ï¼Œä¸»è¦æ”¹åŠ¨å†…å®¹å¦‚ä¸‹ï¼š

1. `requirements.txt` ä¸­å¢åŠ  `gradio==4.43.0` ä¾èµ–ã€‚ä½¿ç”¨ [README.md](https://huggingface.co/spaces/hf-accelerate/model-memory-usage/blob/main/README.md) ä¸­è®¾å®šçš„ Gradio SDK ç‰ˆæœ¬ `4.36.0` å¯èƒ½ä¼šé‡åˆ° [ä¸ pydantic ç‰ˆæœ¬ä¸åŒ¹é…å¯¼è‡´çš„æŠ¥é”™](https://blog.csdn.net/qq_38463737/article/details/142825145)ï¼Œæ•…å‡çº§è‡³ `4.43.0` ç‰ˆæœ¬ã€‚
1. ä¿®æ”¹ `src/app.py` ä¸­ `get_results` æ–¹æ³•ï¼Œä¿®å¤å®˜æ–¹åº”ç”¨ä¸­æ— æ³•åœ¨ Hub ä¸­æ‰¾åˆ°æ¨¡å‹çš„é—®é¢˜ã€‚

```diff
diff --git a/src/app.py b/src/app.py
index 7a5e23e..500023a 100644
--- a/src/app.py
+++ b/src/app.py
@@ -7,6 +7,8 @@ from model_utils import calculate_memory, get_model


 def get_results(model_name: str, library: str, options: list, access_token: str):
+    if access_token == "":
+        access_token = None
     model = get_model(model_name, library, access_token)
     # try:
     #     has_discussion = check_for_discussion(model_name)
```

> ä¸åŸå§‹ç‰ˆæœ¬å…·ä½“åŒºåˆ«å¯è§ [diff](https://github.com/AlphaHinex/model-memory-usage/compare/main...hotfix)ã€‚

Python 3.8
----------

```bash
# conda create -n mmu-env python=3.8 -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/
$ conda create -n mmu-env python=3.8
$ conda activate mmu-env
```

> conda ç¯å¢ƒå®‰è£…å¯å‚ç…§ [miniconda](https://alphahinex.github.io/2024/01/14/jupyter-lab-in-action/)ã€‚

éƒ¨ç½²
----

```bash
$ git clone https://github.com/AlphaHinex/model-memory-usage.git
$ cd model-memory-usage

# pip install -r requirements.txt -i http://192.168.1.200/local/proxy/pypi/web/simple --trusted-host 192.168.1.200
# pip install -r requirements.txt
$ pip install -r requirements.txt -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple

# python src/app.py
$ HF_ENDPOINT=https://hf-mirror.com python src/app.py
```

`Model Name or URL` å¤„è¾“å…¥ `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B`ï¼Œåœ¨ `Model Precision` é€‰æ‹©è¦ä¼°ç®—çš„ç²¾åº¦ï¼Œç‚¹å‡» `Calculate Memory Usage`ï¼š

![](/contents/model-memory-usage/cover.png)
